{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sudee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>What are some of the best side dishes for crab...</td>\n",
       "      <td>What are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>Which is more advisable and better material fo...</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                   How do I play Pokémon GO in Korea?   \n",
       "368101  What are some of the best side dishes for crab...   \n",
       "70497   Which is more advisable and better material fo...   \n",
       "226567       How do I improve logical programming skills?   \n",
       "73186              How close we are to see 3rd world war?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "8067                   How do I play Pokémon GO in China?             0  \n",
       "368101  What are some good side dishes for buffalo chi...             0  \n",
       "70497       What is the best server setup for buddypress?             0  \n",
       "226567  How can I improve my logical skills for progra...             1  \n",
       "73186                       How close is a World War III?             1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.sample(100000,random_state=42)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "    \n",
    "    q = str(q).lower().strip()\n",
    "    \n",
    "    # Replace certain special characters with their string equivalents\n",
    "    q = q.replace('%', ' percent')\n",
    "    q = q.replace('$', ' dollar ')\n",
    "    q = q.replace('₹', ' rupee ')\n",
    "    q = q.replace('€', ' euro ')\n",
    "    q = q.replace('@', ' at ')\n",
    "    \n",
    "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
    "    q = q.replace('[math]', '')\n",
    "    \n",
    "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
    "    q = q.replace(',000,000,000 ', 'b ')\n",
    "    q = q.replace(',000,000 ', 'm ')\n",
    "    q = q.replace(',000 ', 'k ')\n",
    "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
    "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
    "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
    "    \n",
    "    # Decontracting words\n",
    "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "    # https://stackoverflow.com/a/19794953\n",
    "    contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    q_decontracted = []\n",
    "\n",
    "    for word in q.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "\n",
    "        q_decontracted.append(word)\n",
    "\n",
    "    q = ' '.join(q_decontracted)\n",
    "    q = q.replace(\"'ve\", \" have\")\n",
    "    q = q.replace(\"n't\", \" not\")\n",
    "    q = q.replace(\"'re\", \" are\")\n",
    "    q = q.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # Removing HTML tags\n",
    "    q = BeautifulSoup(q)\n",
    "    q = q.get_text()\n",
    "    \n",
    "    # Remove punctuations\n",
    "    pattern = re.compile('\\W')\n",
    "    q = re.sub(pattern, ' ', q).strip()\n",
    "\n",
    "    \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am done already already   i was not done'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"I'm Done Already already!. I wasn't <b>done</b>?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "8067                    how do i play pokémon go in china             0  \n",
       "368101  what are some good side dishes for buffalo chi...             0  \n",
       "70497        what is the best server setup for buddypress             0  \n",
       "226567  how can i improve my logical skills for progra...             1  \n",
       "73186                        how close is a world war iii             1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['question1'] = new_df['question1'].apply(preprocess)\n",
    "new_df['question2'] = new_df['question2'].apply(preprocess)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING NEW FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                    how do i play pokémon go in china             0   \n",
       "368101  what are some good side dishes for buffalo chi...             0   \n",
       "70497        what is the best server setup for buddypress             0   \n",
       "226567  how can i improve my logical skills for progra...             1   \n",
       "73186                        how close is a world war iii             1   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  \n",
       "8067        33      33             8             8  \n",
       "368101      52      50            11             9  \n",
       "70497       95      44            17             8  \n",
       "226567      43      51             7             9  \n",
       "73186       37      28             9             7  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['q1_len'] = new_df['question1'].str.len() \n",
    "new_df['q2_len'] = new_df['question2'].str.len()\n",
    "new_df['q1_num_words'] = new_df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "new_df['q2_num_words'] = new_df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                    how do i play pokémon go in china             0   \n",
       "368101  what are some good side dishes for buffalo chi...             0   \n",
       "70497        what is the best server setup for buddypress             0   \n",
       "226567  how can i improve my logical skills for progra...             1   \n",
       "73186                        how close is a world war iii             1   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  word_common  \n",
       "8067        33      33             8             8            7  \n",
       "368101      52      50            11             9            6  \n",
       "70497       95      44            17             8            2  \n",
       "226567      43      51             7             9            6  \n",
       "73186       37      28             9             7            4  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['word_common'] = new_df.apply(common_words, axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                    how do i play pokémon go in china             0   \n",
       "368101  what are some good side dishes for buffalo chi...             0   \n",
       "70497        what is the best server setup for buddypress             0   \n",
       "226567  how can i improve my logical skills for progra...             1   \n",
       "73186                        how close is a world war iii             1   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  word_common  word_total  \n",
       "8067        33      33             8             8            7          16  \n",
       "368101      52      50            11             9            6          20  \n",
       "70497       95      44            17             8            2          25  \n",
       "226567      43      51             7             9            6          16  \n",
       "73186       37      28             9             7            4          16  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['word_total'] = new_df.apply(total_words, axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>Common_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                    how do i play pokémon go in china             0   \n",
       "368101  what are some good side dishes for buffalo chi...             0   \n",
       "70497        what is the best server setup for buddypress             0   \n",
       "226567  how can i improve my logical skills for progra...             1   \n",
       "73186                        how close is a world war iii             1   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  word_common  word_total  \\\n",
       "8067        33      33             8             8            7          16   \n",
       "368101      52      50            11             9            6          20   \n",
       "70497       95      44            17             8            2          25   \n",
       "226567      43      51             7             9            6          16   \n",
       "73186       37      28             9             7            4          16   \n",
       "\n",
       "        Common_word_ratio  \n",
       "8067                 0.44  \n",
       "368101               0.30  \n",
       "70497                0.08  \n",
       "226567               0.38  \n",
       "73186                0.25  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Common_word_ratio'] = round(new_df['word_common']/new_df['word_total'],2)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Features\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def fetch_token_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_features = new_df.apply(fetch_token_features, axis=1)\n",
    "\n",
    "new_df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "new_df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "new_df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "new_df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "new_df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "new_df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "new_df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "new_df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>word_total</th>\n",
       "      <th>Common_word_ratio</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.545450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.444440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                    how do i play pokémon go in china             0   \n",
       "368101  what are some good side dishes for buffalo chi...             0   \n",
       "70497        what is the best server setup for buddypress             0   \n",
       "226567  how can i improve my logical skills for progra...             1   \n",
       "73186                        how close is a world war iii             1   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  ...  word_total  \\\n",
       "8067        33      33             8             8  ...          16   \n",
       "368101      52      50            11             9  ...          20   \n",
       "70497       95      44            17             8  ...          25   \n",
       "226567      43      51             7             9  ...          16   \n",
       "73186       37      28             9             7  ...          16   \n",
       "\n",
       "        Common_word_ratio   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "8067                 0.44  0.749981  0.749981  0.999975  0.999975  0.874989   \n",
       "368101               0.30  0.399992  0.399992  0.999975  0.666656  0.666659   \n",
       "70497                0.08  0.000000  0.000000  0.499988  0.249997  0.249997   \n",
       "226567               0.38  0.999975  0.999975  0.666644  0.399992  0.857131   \n",
       "73186                0.25  0.749981  0.599988  0.333322  0.249994  0.571420   \n",
       "\n",
       "         ctc_max  last_word_eq  first_word_eq  \n",
       "8067    0.874989           0.0            1.0  \n",
       "368101  0.545450           0.0            1.0  \n",
       "70497   0.124999           0.0            0.0  \n",
       "226567  0.666659           0.0            1.0  \n",
       "73186   0.444440           0.0            1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "def fetch_length_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    length_features = [0.0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1) if strs else 0\n",
    "    \n",
    "    return length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_features = new_df.apply(fetch_length_features, axis=1)\n",
    "\n",
    "new_df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\n",
    "new_df['mean_len'] = list(map(lambda x: x[1], length_features))\n",
    "new_df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>8067</td>\n",
       "      <td>15738</td>\n",
       "      <td>15739</td>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>368101</td>\n",
       "      <td>12736</td>\n",
       "      <td>104117</td>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.545450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>70497</td>\n",
       "      <td>121486</td>\n",
       "      <td>121487</td>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>226567</td>\n",
       "      <td>254474</td>\n",
       "      <td>258192</td>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>73186</td>\n",
       "      <td>48103</td>\n",
       "      <td>3062</td>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.444440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "8067      8067   15738   15739   \n",
       "368101  368101   12736  104117   \n",
       "70497    70497  121486  121487   \n",
       "226567  226567  254474  258192   \n",
       "73186    73186   48103    3062   \n",
       "\n",
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "8067                    how do i play pokémon go in china             0   \n",
       "368101  what are some good side dishes for buffalo chi...             0   \n",
       "70497        what is the best server setup for buddypress             0   \n",
       "226567  how can i improve my logical skills for progra...             1   \n",
       "73186                        how close is a world war iii             1   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  ...   cwc_max   csc_min  \\\n",
       "8067        33      33             8             8  ...  0.749981  0.999975   \n",
       "368101      52      50            11             9  ...  0.399992  0.999975   \n",
       "70497       95      44            17             8  ...  0.000000  0.499988   \n",
       "226567      43      51             7             9  ...  0.999975  0.666644   \n",
       "73186       37      28             9             7  ...  0.599988  0.333322   \n",
       "\n",
       "         csc_max   ctc_min   ctc_max  last_word_eq  first_word_eq  \\\n",
       "8067    0.999975  0.874989  0.874989           0.0            1.0   \n",
       "368101  0.666656  0.666659  0.545450           0.0            1.0   \n",
       "70497   0.249997  0.249997  0.124999           0.0            0.0   \n",
       "226567  0.399992  0.857131  0.666659           0.0            1.0   \n",
       "73186   0.249994  0.571420  0.444440           0.0            1.0   \n",
       "\n",
       "        abs_len_diff  mean_len  longest_substr_ratio  \n",
       "8067             0.0       8.0              0.823529  \n",
       "368101           2.0      10.0              0.333333  \n",
       "70497            8.0      12.0              0.111111  \n",
       "226567           2.0       8.0              0.272727  \n",
       "73186            2.0       8.0              0.344828  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  \n",
       "8067                    how do i play pokémon go in china  \n",
       "368101  what are some good side dishes for buffalo chi...  \n",
       "70497        what is the best server setup for buddypress  \n",
       "226567  how can i improve my logical skills for progra...  \n",
       "73186                        how close is a world war iii  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_df = new_df[['question1','question2']]\n",
    "ques_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>Common_word_ratio</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.545450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.444440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate  q1_len  q2_len  q1_num_words  q2_num_words  word_common  \\\n",
       "8067               0      33      33             8             8            7   \n",
       "368101             0      52      50            11             9            6   \n",
       "70497              0      95      44            17             8            2   \n",
       "226567             1      43      51             7             9            6   \n",
       "73186              1      37      28             9             7            4   \n",
       "\n",
       "        word_total  Common_word_ratio   cwc_min   cwc_max   csc_min   csc_max  \\\n",
       "8067            16               0.44  0.749981  0.749981  0.999975  0.999975   \n",
       "368101          20               0.30  0.399992  0.399992  0.999975  0.666656   \n",
       "70497           25               0.08  0.000000  0.000000  0.499988  0.249997   \n",
       "226567          16               0.38  0.999975  0.999975  0.666644  0.399992   \n",
       "73186           16               0.25  0.749981  0.599988  0.333322  0.249994   \n",
       "\n",
       "         ctc_min   ctc_max  last_word_eq  first_word_eq  abs_len_diff  \\\n",
       "8067    0.874989  0.874989           0.0            1.0           0.0   \n",
       "368101  0.666659  0.545450           0.0            1.0           2.0   \n",
       "70497   0.249997  0.124999           0.0            0.0           8.0   \n",
       "226567  0.857131  0.666659           0.0            1.0           2.0   \n",
       "73186   0.571420  0.444440           0.0            1.0           2.0   \n",
       "\n",
       "        mean_len  longest_substr_ratio  \n",
       "8067         8.0              0.823529  \n",
       "368101      10.0              0.333333  \n",
       "70497       12.0              0.111111  \n",
       "226567       8.0              0.272727  \n",
       "73186        8.0              0.344828  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Glove Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded at: C:\\Users\\sudee/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Resume download\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "print(f\"Model downloaded at: {word2vec_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load the Glove model properly\n",
    "word2vec_model = api.load(\"glove-wiki-gigaword-50\") \n",
    "\n",
    "# Save the model in Word2Vec format (text-based)\n",
    "word2vec_model.save_word2vec_format(\"word2vec.txt\", binary=False)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('truck', 0.92085862159729), ('cars', 0.8870189785957336), ('vehicle', 0.8833683729171753), ('driver', 0.8464019298553467), ('driving', 0.8384189009666443)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load the Glove model in Word2Vec format\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(\"word2vec.txt\", binary=False)\n",
    "\n",
    "# Test similarity\n",
    "print(word2vec_model.most_similar(\"car\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sudee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea]</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, china]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "      <td>[what, are, some, good, side, dishes, for, buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "      <td>[what, is, the, best, server, setup, for, budd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>[how, do, i, improve, logical, programming, sk...</td>\n",
       "      <td>[how, can, i, improve, my, logical, skills, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>[how, close, we, are, to, see, 3rd, world, war]</td>\n",
       "      <td>[how, close, is, a, world, war, iii]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  \\\n",
       "8067                    how do i play pokémon go in china   \n",
       "368101  what are some good side dishes for buffalo chi...   \n",
       "70497        what is the best server setup for buddypress   \n",
       "226567  how can i improve my logical skills for progra...   \n",
       "73186                        how close is a world war iii   \n",
       "\n",
       "                                                q1_tokens  \\\n",
       "8067           [how, do, i, play, pokémon, go, in, korea]   \n",
       "368101  [what, are, some, of, the, best, side, dishes,...   \n",
       "70497   [which, is, more, advisable, and, better, mate...   \n",
       "226567  [how, do, i, improve, logical, programming, sk...   \n",
       "73186     [how, close, we, are, to, see, 3rd, world, war]   \n",
       "\n",
       "                                                q2_tokens  \n",
       "8067           [how, do, i, play, pokémon, go, in, china]  \n",
       "368101  [what, are, some, good, side, dishes, for, buf...  \n",
       "70497   [what, is, the, best, server, setup, for, budd...  \n",
       "226567  [how, can, i, improve, my, logical, skills, fo...  \n",
       "73186                [how, close, is, a, world, war, iii]  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Convert to lowercase and tokenize\n",
    "ques_df['q1_tokens'] = ques_df['question1'].apply(lambda x: word_tokenize(x.lower()))\n",
    "ques_df['q2_tokens'] = ques_df['question2'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "ques_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a list of words to a vector\n",
    "def sentence_to_vector(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both questions into vectors\n",
    "ques_df['q1_vector'] = ques_df['q1_tokens'].apply(lambda x: sentence_to_vector(x, word2vec_model))\n",
    "ques_df['q2_vector'] = ques_df['q2_tokens'].apply(lambda x: sentence_to_vector(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Assuming q1_vector and q2_vector are already in the DataFrame\n",
    "ques_df['q1_vector'] =ques_df['q1_vector'].apply(np.array)  # Ensure they are NumPy arrays\n",
    "ques_df['q2_vector'] = ques_df['q2_vector'].apply(np.array)\n",
    "\n",
    "# Compute absolute difference |q1 - q2|\n",
    "ques_df['abs_diff'] = ques_df.apply(lambda row: np.abs(row['q1_vector'] - row['q2_vector']), axis=1)\n",
    "\n",
    "# Compute element-wise product q1 * q2\n",
    "ques_df['elementwise_product'] = ques_df.apply(lambda row: row['q1_vector'] * row['q2_vector'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "      <th>q1_vector</th>\n",
       "      <th>q2_vector</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>elementwise_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>how do i play pokémon go in korea</td>\n",
       "      <td>how do i play pokémon go in china</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, korea]</td>\n",
       "      <td>[how, do, i, play, pokémon, go, in, china]</td>\n",
       "      <td>[0.048978735, 0.12111999, -0.08994362, 0.21367...</td>\n",
       "      <td>[0.058528736, 0.11420874, -0.14329837, 0.30333...</td>\n",
       "      <td>[0.0095500015, 0.006911248, 0.053354755, 0.089...</td>\n",
       "      <td>[0.0028666635, 0.013832962, 0.012888774, 0.064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>what are some of the best side dishes for crab...</td>\n",
       "      <td>what are some good side dishes for buffalo chi...</td>\n",
       "      <td>[what, are, some, of, the, best, side, dishes,...</td>\n",
       "      <td>[what, are, some, good, side, dishes, for, buf...</td>\n",
       "      <td>[0.4118309, 0.21178155, -0.43707272, 0.0196644...</td>\n",
       "      <td>[0.24862221, 0.08570189, -0.46412998, -0.15518...</td>\n",
       "      <td>[0.1632087, 0.12607965, 0.02705726, 0.17484868...</td>\n",
       "      <td>[0.10239031, 0.018150078, 0.20285855, -0.00305...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>which is more advisable and better material fo...</td>\n",
       "      <td>what is the best server setup for buddypress</td>\n",
       "      <td>[which, is, more, advisable, and, better, mate...</td>\n",
       "      <td>[what, is, the, best, server, setup, for, budd...</td>\n",
       "      <td>[0.20822841, 0.023662375, 0.016414564, -0.0337...</td>\n",
       "      <td>[0.23382142, 0.15573585, -0.07020001, 0.386168...</td>\n",
       "      <td>[0.025593013, 0.13207348, 0.08661458, 0.419886...</td>\n",
       "      <td>[0.048688263, 0.0036850802, -0.0011523026, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>how do i improve logical programming skills</td>\n",
       "      <td>how can i improve my logical skills for progra...</td>\n",
       "      <td>[how, do, i, improve, logical, programming, sk...</td>\n",
       "      <td>[how, can, i, improve, my, logical, skills, fo...</td>\n",
       "      <td>[0.22090183, -0.027280003, -0.12204414, -0.079...</td>\n",
       "      <td>[0.21504362, 0.16173556, -0.07358255, -0.11427...</td>\n",
       "      <td>[0.0058582127, 0.18901557, 0.048461586, 0.0351...</td>\n",
       "      <td>[0.04750353, -0.0044121468, 0.008980319, 0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>how close we are to see 3rd world war</td>\n",
       "      <td>how close is a world war iii</td>\n",
       "      <td>[how, close, we, are, to, see, 3rd, world, war]</td>\n",
       "      <td>[how, close, is, a, world, war, iii]</td>\n",
       "      <td>[0.33585003, 0.11932678, 0.13839345, -0.159580...</td>\n",
       "      <td>[0.3623257, 0.38533857, -0.081577145, 0.074711...</td>\n",
       "      <td>[0.026475668, 0.2660118, 0.21997058, 0.2342924...</td>\n",
       "      <td>[0.1216871, 0.04598121, -0.011289742, -0.01192...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "8067                    how do i play pokémon go in korea   \n",
       "368101  what are some of the best side dishes for crab...   \n",
       "70497   which is more advisable and better material fo...   \n",
       "226567        how do i improve logical programming skills   \n",
       "73186               how close we are to see 3rd world war   \n",
       "\n",
       "                                                question2  \\\n",
       "8067                    how do i play pokémon go in china   \n",
       "368101  what are some good side dishes for buffalo chi...   \n",
       "70497        what is the best server setup for buddypress   \n",
       "226567  how can i improve my logical skills for progra...   \n",
       "73186                        how close is a world war iii   \n",
       "\n",
       "                                                q1_tokens  \\\n",
       "8067           [how, do, i, play, pokémon, go, in, korea]   \n",
       "368101  [what, are, some, of, the, best, side, dishes,...   \n",
       "70497   [which, is, more, advisable, and, better, mate...   \n",
       "226567  [how, do, i, improve, logical, programming, sk...   \n",
       "73186     [how, close, we, are, to, see, 3rd, world, war]   \n",
       "\n",
       "                                                q2_tokens  \\\n",
       "8067           [how, do, i, play, pokémon, go, in, china]   \n",
       "368101  [what, are, some, good, side, dishes, for, buf...   \n",
       "70497   [what, is, the, best, server, setup, for, budd...   \n",
       "226567  [how, can, i, improve, my, logical, skills, fo...   \n",
       "73186                [how, close, is, a, world, war, iii]   \n",
       "\n",
       "                                                q1_vector  \\\n",
       "8067    [0.048978735, 0.12111999, -0.08994362, 0.21367...   \n",
       "368101  [0.4118309, 0.21178155, -0.43707272, 0.0196644...   \n",
       "70497   [0.20822841, 0.023662375, 0.016414564, -0.0337...   \n",
       "226567  [0.22090183, -0.027280003, -0.12204414, -0.079...   \n",
       "73186   [0.33585003, 0.11932678, 0.13839345, -0.159580...   \n",
       "\n",
       "                                                q2_vector  \\\n",
       "8067    [0.058528736, 0.11420874, -0.14329837, 0.30333...   \n",
       "368101  [0.24862221, 0.08570189, -0.46412998, -0.15518...   \n",
       "70497   [0.23382142, 0.15573585, -0.07020001, 0.386168...   \n",
       "226567  [0.21504362, 0.16173556, -0.07358255, -0.11427...   \n",
       "73186   [0.3623257, 0.38533857, -0.081577145, 0.074711...   \n",
       "\n",
       "                                                 abs_diff  \\\n",
       "8067    [0.0095500015, 0.006911248, 0.053354755, 0.089...   \n",
       "368101  [0.1632087, 0.12607965, 0.02705726, 0.17484868...   \n",
       "70497   [0.025593013, 0.13207348, 0.08661458, 0.419886...   \n",
       "226567  [0.0058582127, 0.18901557, 0.048461586, 0.0351...   \n",
       "73186   [0.026475668, 0.2660118, 0.21997058, 0.2342924...   \n",
       "\n",
       "                                      elementwise_product  \n",
       "8067    [0.0028666635, 0.013832962, 0.012888774, 0.064...  \n",
       "368101  [0.10239031, 0.018150078, 0.20285855, -0.00305...  \n",
       "70497   [0.048688263, 0.0036850802, -0.0011523026, -0....  \n",
       "226567  [0.04750353, -0.0044121468, 0.008980319, 0.009...  \n",
       "73186   [0.1216871, 0.04598121, -0.011289742, -0.01192...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_vector</th>\n",
       "      <th>q2_vector</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>elementwise_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>[0.048978735, 0.12111999, -0.08994362, 0.21367...</td>\n",
       "      <td>[0.058528736, 0.11420874, -0.14329837, 0.30333...</td>\n",
       "      <td>[0.0095500015, 0.006911248, 0.053354755, 0.089...</td>\n",
       "      <td>[0.0028666635, 0.013832962, 0.012888774, 0.064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>[0.4118309, 0.21178155, -0.43707272, 0.0196644...</td>\n",
       "      <td>[0.24862221, 0.08570189, -0.46412998, -0.15518...</td>\n",
       "      <td>[0.1632087, 0.12607965, 0.02705726, 0.17484868...</td>\n",
       "      <td>[0.10239031, 0.018150078, 0.20285855, -0.00305...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>[0.20822841, 0.023662375, 0.016414564, -0.0337...</td>\n",
       "      <td>[0.23382142, 0.15573585, -0.07020001, 0.386168...</td>\n",
       "      <td>[0.025593013, 0.13207348, 0.08661458, 0.419886...</td>\n",
       "      <td>[0.048688263, 0.0036850802, -0.0011523026, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>[0.22090183, -0.027280003, -0.12204414, -0.079...</td>\n",
       "      <td>[0.21504362, 0.16173556, -0.07358255, -0.11427...</td>\n",
       "      <td>[0.0058582127, 0.18901557, 0.048461586, 0.0351...</td>\n",
       "      <td>[0.04750353, -0.0044121468, 0.008980319, 0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>[0.33585003, 0.11932678, 0.13839345, -0.159580...</td>\n",
       "      <td>[0.3623257, 0.38533857, -0.081577145, 0.074711...</td>\n",
       "      <td>[0.026475668, 0.2660118, 0.21997058, 0.2342924...</td>\n",
       "      <td>[0.1216871, 0.04598121, -0.011289742, -0.01192...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                q1_vector  \\\n",
       "8067    [0.048978735, 0.12111999, -0.08994362, 0.21367...   \n",
       "368101  [0.4118309, 0.21178155, -0.43707272, 0.0196644...   \n",
       "70497   [0.20822841, 0.023662375, 0.016414564, -0.0337...   \n",
       "226567  [0.22090183, -0.027280003, -0.12204414, -0.079...   \n",
       "73186   [0.33585003, 0.11932678, 0.13839345, -0.159580...   \n",
       "\n",
       "                                                q2_vector  \\\n",
       "8067    [0.058528736, 0.11420874, -0.14329837, 0.30333...   \n",
       "368101  [0.24862221, 0.08570189, -0.46412998, -0.15518...   \n",
       "70497   [0.23382142, 0.15573585, -0.07020001, 0.386168...   \n",
       "226567  [0.21504362, 0.16173556, -0.07358255, -0.11427...   \n",
       "73186   [0.3623257, 0.38533857, -0.081577145, 0.074711...   \n",
       "\n",
       "                                                 abs_diff  \\\n",
       "8067    [0.0095500015, 0.006911248, 0.053354755, 0.089...   \n",
       "368101  [0.1632087, 0.12607965, 0.02705726, 0.17484868...   \n",
       "70497   [0.025593013, 0.13207348, 0.08661458, 0.419886...   \n",
       "226567  [0.0058582127, 0.18901557, 0.048461586, 0.0351...   \n",
       "73186   [0.026475668, 0.2660118, 0.21997058, 0.2342924...   \n",
       "\n",
       "                                      elementwise_product  \n",
       "8067    [0.0028666635, 0.013832962, 0.012888774, 0.064...  \n",
       "368101  [0.10239031, 0.018150078, 0.20285855, -0.00305...  \n",
       "70497   [0.048688263, 0.0036850802, -0.0011523026, -0....  \n",
       "226567  [0.04750353, -0.0044121468, 0.008980319, 0.009...  \n",
       "73186   [0.1216871, 0.04598121, -0.011289742, -0.01192...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = ques_df[['q1_vector', 'q2_vector', 'abs_diff', 'elementwise_product']].copy()\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>Common_word_ratio</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>q1_vector</th>\n",
       "      <th>q2_vector</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>elementwise_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>[0.048978735, 0.12111999, -0.08994362, 0.21367...</td>\n",
       "      <td>[0.058528736, 0.11420874, -0.14329837, 0.30333...</td>\n",
       "      <td>[0.0095500015, 0.006911248, 0.053354755, 0.089...</td>\n",
       "      <td>[0.0028666635, 0.013832962, 0.012888774, 0.064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[0.4118309, 0.21178155, -0.43707272, 0.0196644...</td>\n",
       "      <td>[0.24862221, 0.08570189, -0.46412998, -0.15518...</td>\n",
       "      <td>[0.1632087, 0.12607965, 0.02705726, 0.17484868...</td>\n",
       "      <td>[0.10239031, 0.018150078, 0.20285855, -0.00305...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>[0.20822841, 0.023662375, 0.016414564, -0.0337...</td>\n",
       "      <td>[0.23382142, 0.15573585, -0.07020001, 0.386168...</td>\n",
       "      <td>[0.025593013, 0.13207348, 0.08661458, 0.419886...</td>\n",
       "      <td>[0.048688263, 0.0036850802, -0.0011523026, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>[0.22090183, -0.027280003, -0.12204414, -0.079...</td>\n",
       "      <td>[0.21504362, 0.16173556, -0.07358255, -0.11427...</td>\n",
       "      <td>[0.0058582127, 0.18901557, 0.048461586, 0.0351...</td>\n",
       "      <td>[0.04750353, -0.0044121468, 0.008980319, 0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>[0.33585003, 0.11932678, 0.13839345, -0.159580...</td>\n",
       "      <td>[0.3623257, 0.38533857, -0.081577145, 0.074711...</td>\n",
       "      <td>[0.026475668, 0.2660118, 0.21997058, 0.2342924...</td>\n",
       "      <td>[0.1216871, 0.04598121, -0.011289742, -0.01192...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate  q1_len  q2_len  q1_num_words  q2_num_words  word_common  \\\n",
       "8067               0      33      33             8             8            7   \n",
       "368101             0      52      50            11             9            6   \n",
       "70497              0      95      44            17             8            2   \n",
       "226567             1      43      51             7             9            6   \n",
       "73186              1      37      28             9             7            4   \n",
       "\n",
       "        word_total  Common_word_ratio   cwc_min   cwc_max  ...   ctc_max  \\\n",
       "8067            16               0.44  0.749981  0.749981  ...  0.874989   \n",
       "368101          20               0.30  0.399992  0.399992  ...  0.545450   \n",
       "70497           25               0.08  0.000000  0.000000  ...  0.124999   \n",
       "226567          16               0.38  0.999975  0.999975  ...  0.666659   \n",
       "73186           16               0.25  0.749981  0.599988  ...  0.444440   \n",
       "\n",
       "        last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "8067             0.0            1.0           0.0       8.0   \n",
       "368101           0.0            1.0           2.0      10.0   \n",
       "70497            0.0            0.0           8.0      12.0   \n",
       "226567           0.0            1.0           2.0       8.0   \n",
       "73186            0.0            1.0           2.0       8.0   \n",
       "\n",
       "        longest_substr_ratio  \\\n",
       "8067                0.823529   \n",
       "368101              0.333333   \n",
       "70497               0.111111   \n",
       "226567              0.272727   \n",
       "73186               0.344828   \n",
       "\n",
       "                                                q1_vector  \\\n",
       "8067    [0.048978735, 0.12111999, -0.08994362, 0.21367...   \n",
       "368101  [0.4118309, 0.21178155, -0.43707272, 0.0196644...   \n",
       "70497   [0.20822841, 0.023662375, 0.016414564, -0.0337...   \n",
       "226567  [0.22090183, -0.027280003, -0.12204414, -0.079...   \n",
       "73186   [0.33585003, 0.11932678, 0.13839345, -0.159580...   \n",
       "\n",
       "                                                q2_vector  \\\n",
       "8067    [0.058528736, 0.11420874, -0.14329837, 0.30333...   \n",
       "368101  [0.24862221, 0.08570189, -0.46412998, -0.15518...   \n",
       "70497   [0.23382142, 0.15573585, -0.07020001, 0.386168...   \n",
       "226567  [0.21504362, 0.16173556, -0.07358255, -0.11427...   \n",
       "73186   [0.3623257, 0.38533857, -0.081577145, 0.074711...   \n",
       "\n",
       "                                                 abs_diff  \\\n",
       "8067    [0.0095500015, 0.006911248, 0.053354755, 0.089...   \n",
       "368101  [0.1632087, 0.12607965, 0.02705726, 0.17484868...   \n",
       "70497   [0.025593013, 0.13207348, 0.08661458, 0.419886...   \n",
       "226567  [0.0058582127, 0.18901557, 0.048461586, 0.0351...   \n",
       "73186   [0.026475668, 0.2660118, 0.21997058, 0.2342924...   \n",
       "\n",
       "                                      elementwise_product  \n",
       "8067    [0.0028666635, 0.013832962, 0.012888774, 0.064...  \n",
       "368101  [0.10239031, 0.018150078, 0.20285855, -0.00305...  \n",
       "70497   [0.048688263, 0.0036850802, -0.0011523026, -0....  \n",
       "226567  [0.04750353, -0.0044121468, 0.008980319, 0.009...  \n",
       "73186   [0.1216871, 0.04598121, -0.011289742, -0.01192...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([final_df, temp_df], axis=1)\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Extract vector columns and flatten them\n",
    "def flatten_vectors(df, column_name):\n",
    "    return np.stack(df[column_name].values)  # Converts lists into a 2D NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1_features = flatten_vectors(final_df, \"q1_vector\")  # Shape: (num_samples, vec1_dim)\n",
    "vec2_features = flatten_vectors(final_df, \"q2_vector\")  # Shape: (num_samples, vec2_dim)\n",
    "vecdiff_features = flatten_vectors(final_df, \"abs_diff\")\n",
    "vecmultiply_features = flatten_vectors(final_df, \"elementwise_product\")\n",
    "# Extract numerical features\n",
    "numerical_features = final_df.drop(columns=[\"is_duplicate\", \"q1_vector\", \"q2_vector\", \"abs_diff\", \"elementwise_product\"]).values  # Shape: (num_samples, num_numerical_features)\n",
    "\n",
    "# Concatenate all features into one matrix\n",
    "X = np.hstack((numerical_features, vec1_features, vec2_features, vecdiff_features, vecmultiply_features))  # Final shape: (num_samples, total_features)\n",
    "\n",
    "# Extract target variable\n",
    "y = final_df[\"is_duplicate\"].values  # Ensure y is 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.30000000e+01,  3.30000000e+01,  8.00000000e+00, ...,\n",
       "        -4.48666455e-04,  2.59953104e-02,  4.79930416e-02],\n",
       "       [ 5.20000000e+01,  5.00000000e+01,  1.10000000e+01, ...,\n",
       "        -9.59308352e-03,  1.49802687e-02, -2.65978687e-02],\n",
       "       [ 9.50000000e+01,  4.40000000e+01,  1.70000000e+01, ...,\n",
       "         1.41693908e-03, -3.35978111e-04, -1.18861655e-02],\n",
       "       ...,\n",
       "       [ 4.20000000e+01,  4.10000000e+01,  7.00000000e+00, ...,\n",
       "         8.73979181e-02,  1.17329806e-02,  9.82841570e-03],\n",
       "       [ 3.40000000e+01,  4.60000000e+01,  6.00000000e+00, ...,\n",
       "        -9.33687575e-03,  2.25696489e-02, -1.81639064e-02],\n",
       "       [ 2.20000000e+01,  1.90000000e+01,  5.00000000e+00, ...,\n",
       "         4.42053610e-03,  4.39473763e-02,  1.67480990e-01]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (70000, 218)\n",
      "X_val shape:   (15000, 218)\n",
      "X_test shape:  (15000, 218)\n",
      "y_train shape: (70000,)\n",
      "y_val shape:   (15000,)\n",
      "y_test shape:  (15000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, split your dataset into training and temporary sets.\n",
    "# For example, 70% for training and 30% for temporary.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Now, split the temporary set equally into validation and test sets.\n",
    "# This gives you 15% of the data for validation and 15% for testing.\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Ensure the correct data types for all sets.\n",
    "X_train = np.array(X_train, dtype=np.float64)\n",
    "X_val   = np.array(X_val, dtype=np.float64)\n",
    "X_test  = np.array(X_test, dtype=np.float64)\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.int64).ravel()\n",
    "y_val   = np.array(y_val, dtype=np.int64).ravel()\n",
    "y_test  = np.array(y_test, dtype=np.int64).ravel()\n",
    "\n",
    "# Optional: Print shapes to confirm the splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:  \", X_val.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:  \", y_val.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRYING OUT NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training will stop and the best weights (from the lowest validation loss) will be restored.\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=15, min_delta=0.0001, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">112,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">106,191</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m112,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m207\u001b[0m)            │       \u001b[38;5;34m106,191\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m207\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m26,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,072</span> (957.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m245,072\u001b[0m (957.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,072</span> (957.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m245,072\u001b[0m (957.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input shape (218 features)\n",
    "input_shape = (218,)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(512, activation='relu'),             # First Dense layer with 512 neurons\n",
    "    Dropout(0.3),                              # Dropout with rate 0.1\n",
    "    Dense(207, activation='relu'),             # Second Dense layer with 207 neurons\n",
    "    Dropout(0.3),                              # Dropout with rate ~0.3031\n",
    "    Dense(128, activation='relu'), \n",
    "    Dropout(0.3),                              # Third Dense layer with 128 neurons                      \n",
    "    Dense(1, activation='sigmoid')             # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Create the Adam optimizer with the specified learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and accuracy as a metric\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6446 - loss: 0.6374 - val_accuracy: 0.7197 - val_loss: 0.5108\n",
      "Epoch 2/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.5021 - val_accuracy: 0.7419 - val_loss: 0.4910\n",
      "Epoch 3/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.4854 - val_accuracy: 0.7504 - val_loss: 0.4679\n",
      "Epoch 4/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.4830 - val_accuracy: 0.7553 - val_loss: 0.4657\n",
      "Epoch 5/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7546 - loss: 0.4685 - val_accuracy: 0.7632 - val_loss: 0.4565\n",
      "Epoch 6/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.4678 - val_accuracy: 0.7653 - val_loss: 0.4553\n",
      "Epoch 7/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.4619 - val_accuracy: 0.7646 - val_loss: 0.4648\n",
      "Epoch 8/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.4656 - val_accuracy: 0.7685 - val_loss: 0.4518\n",
      "Epoch 9/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.4607 - val_accuracy: 0.7617 - val_loss: 0.4631\n",
      "Epoch 10/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.4582 - val_accuracy: 0.7653 - val_loss: 0.4567\n",
      "Epoch 11/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.4567 - val_accuracy: 0.7708 - val_loss: 0.4472\n",
      "Epoch 12/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.4556 - val_accuracy: 0.7671 - val_loss: 0.4473\n",
      "Epoch 13/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.4515 - val_accuracy: 0.7570 - val_loss: 0.4566\n",
      "Epoch 14/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.4500 - val_accuracy: 0.7700 - val_loss: 0.4479\n",
      "Epoch 15/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4495 - val_accuracy: 0.7714 - val_loss: 0.4467\n",
      "Epoch 16/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4458 - val_accuracy: 0.7737 - val_loss: 0.4440\n",
      "Epoch 17/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7669 - loss: 0.4484 - val_accuracy: 0.7661 - val_loss: 0.4471\n",
      "Epoch 18/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4448 - val_accuracy: 0.7693 - val_loss: 0.4434\n",
      "Epoch 19/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.4449 - val_accuracy: 0.7706 - val_loss: 0.4388\n",
      "Epoch 20/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7724 - loss: 0.4432 - val_accuracy: 0.7703 - val_loss: 0.4436\n",
      "Epoch 21/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7707 - loss: 0.4454 - val_accuracy: 0.7715 - val_loss: 0.4433\n",
      "Epoch 22/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.4417 - val_accuracy: 0.7769 - val_loss: 0.4366\n",
      "Epoch 23/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4402 - val_accuracy: 0.7765 - val_loss: 0.4376\n",
      "Epoch 24/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.4392 - val_accuracy: 0.7690 - val_loss: 0.4471\n",
      "Epoch 25/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4409 - val_accuracy: 0.7747 - val_loss: 0.4390\n",
      "Epoch 26/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.4394 - val_accuracy: 0.7772 - val_loss: 0.4370\n",
      "Epoch 27/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7776 - loss: 0.4351 - val_accuracy: 0.7739 - val_loss: 0.4409\n",
      "Epoch 28/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.4364 - val_accuracy: 0.7738 - val_loss: 0.4426\n",
      "Epoch 29/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4321 - val_accuracy: 0.7763 - val_loss: 0.4406\n",
      "Epoch 30/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 0.4313 - val_accuracy: 0.7739 - val_loss: 0.4408\n",
      "Epoch 31/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.4291 - val_accuracy: 0.7787 - val_loss: 0.4347\n",
      "Epoch 32/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.4325 - val_accuracy: 0.7757 - val_loss: 0.4541\n",
      "Epoch 33/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4340 - val_accuracy: 0.7779 - val_loss: 0.4385\n",
      "Epoch 34/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.4311 - val_accuracy: 0.7791 - val_loss: 0.4378\n",
      "Epoch 35/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4271 - val_accuracy: 0.7745 - val_loss: 0.4400\n",
      "Epoch 36/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.4260 - val_accuracy: 0.7769 - val_loss: 0.4387\n",
      "Epoch 37/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4280 - val_accuracy: 0.7797 - val_loss: 0.4374\n",
      "Epoch 38/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4263 - val_accuracy: 0.7682 - val_loss: 0.4453\n",
      "Epoch 39/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.4317 - val_accuracy: 0.7740 - val_loss: 0.4468\n",
      "Epoch 40/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4285 - val_accuracy: 0.7789 - val_loss: 0.4363\n",
      "Epoch 41/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.4246 - val_accuracy: 0.7763 - val_loss: 0.4419\n",
      "Epoch 42/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7855 - loss: 0.4222 - val_accuracy: 0.7741 - val_loss: 0.4421\n",
      "Epoch 43/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.4269 - val_accuracy: 0.7789 - val_loss: 0.4344\n",
      "Epoch 44/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.4248 - val_accuracy: 0.7761 - val_loss: 0.4382\n",
      "Epoch 45/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.4221 - val_accuracy: 0.7785 - val_loss: 0.4368\n",
      "Epoch 46/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4218 - val_accuracy: 0.7787 - val_loss: 0.4352\n",
      "Epoch 47/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4245 - val_accuracy: 0.7815 - val_loss: 0.4340\n",
      "Epoch 48/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.4205 - val_accuracy: 0.7785 - val_loss: 0.4383\n",
      "Epoch 49/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7858 - loss: 0.4221 - val_accuracy: 0.7814 - val_loss: 0.4314\n",
      "Epoch 50/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.4207 - val_accuracy: 0.7820 - val_loss: 0.4375\n",
      "Epoch 51/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.4196 - val_accuracy: 0.7796 - val_loss: 0.4358\n",
      "Epoch 52/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.4165 - val_accuracy: 0.7780 - val_loss: 0.4382\n",
      "Epoch 53/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.4150 - val_accuracy: 0.7785 - val_loss: 0.4334\n",
      "Epoch 54/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.4180 - val_accuracy: 0.7786 - val_loss: 0.4364\n",
      "Epoch 55/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.4136 - val_accuracy: 0.7797 - val_loss: 0.4405\n",
      "Epoch 56/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: 0.4146 - val_accuracy: 0.7811 - val_loss: 0.4360\n",
      "Epoch 57/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7863 - loss: 0.4178 - val_accuracy: 0.7777 - val_loss: 0.4421\n",
      "Epoch 58/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7908 - loss: 0.4151 - val_accuracy: 0.7789 - val_loss: 0.4379\n",
      "Epoch 59/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.4134 - val_accuracy: 0.7807 - val_loss: 0.4356\n",
      "Epoch 60/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4142 - val_accuracy: 0.7791 - val_loss: 0.4388\n",
      "Epoch 61/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4190 - val_accuracy: 0.7834 - val_loss: 0.4360\n",
      "Epoch 62/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7927 - loss: 0.4125 - val_accuracy: 0.7829 - val_loss: 0.4318\n",
      "Epoch 63/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.4126 - val_accuracy: 0.7819 - val_loss: 0.4373\n",
      "Epoch 64/100\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.4118 - val_accuracy: 0.7805 - val_loss: 0.4346\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,                # Maximum number of epochs; training may stop earlier due to early stopping.\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop]    # Include early stopping in the training process.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "y_probs = model.predict(X_test).ravel()  # or model.predict(X_test)[:, 0] if output shape is (N,1)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.38282012939453125\n"
     ]
    }
   ],
   "source": [
    "# Compute F1 score for each threshold\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_best_threshold(model, X, threshold):\n",
    "    y_probs = model.predict(X).ravel()  # Get probabilities\n",
    "    return (y_probs >= threshold).astype(int)  # Apply the threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_adjusted = predict_with_best_threshold(model, X_test, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy: 0.7697\n",
      "New F1 Score: 0.7339\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "new_accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "new_f1 = f1_score(y_test, y_pred_adjusted)\n",
    "\n",
    "print(f\"New Accuracy: {new_accuracy:.4f}\")\n",
    "print(f\"New F1 Score: {new_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6781, 2640],\n",
       "       [ 815, 4764]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# for random forest model\n",
    "confusion_matrix(y_test,y_pred_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open('ImprovedNNmodel.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_common_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_total_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_token_features(q1,q2):\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_length_features(q1,q2):\n",
    "    \n",
    "    length_features = [0.0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    \n",
    "    return length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_vector_features(q1,q2, word2vec_model):\n",
    "  \n",
    "    # Tokenize using NLTK\n",
    "   q1_tokens = word_tokenize(q1.lower())\n",
    "   q2_tokens = word_tokenize(q2.lower())\n",
    "\n",
    "   q1_vector = sentence_to_vector(q1_tokens, word2vec_model)\n",
    "   q2_vector = sentence_to_vector(q2_tokens, word2vec_model)\n",
    "\n",
    "    # Compute additional feature representations\n",
    "   abs_diff = np.abs(q1_vector - q2_vector)  # |q1 - q2|\n",
    "   elementwise_mult = q1_vector * q2_vector  # q1 * q2\n",
    "\n",
    "    # Combine all features\n",
    "   vector_features = np.hstack((q1_vector, q2_vector, abs_diff, elementwise_mult))\n",
    "\n",
    "   return vector_features  # Return the feature vector only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_point_creator(q1,q2):\n",
    "    \n",
    "    input_query = []\n",
    "    \n",
    "    # preprocess\n",
    "    q1 = preprocess(q1)\n",
    "    q2 = preprocess(q2)\n",
    "    \n",
    "    # fetch basic features\n",
    "    input_query.append(len(q1))\n",
    "    input_query.append(len(q2))\n",
    "    \n",
    "    input_query.append(len(q1.split(\" \")))\n",
    "    input_query.append(len(q2.split(\" \")))\n",
    "    \n",
    "    input_query.append(test_common_words(q1,q2))\n",
    "    input_query.append(test_total_words(q1,q2))\n",
    "    input_query.append(round(test_common_words(q1,q2)/test_total_words(q1,q2),2))\n",
    "    \n",
    "    # fetch token features\n",
    "    token_features = test_fetch_token_features(q1,q2)\n",
    "    input_query.extend(token_features)\n",
    "    \n",
    "    # fetch length based features\n",
    "    length_features = test_fetch_length_features(q1,q2)\n",
    "    input_query.extend(length_features)\n",
    "   \n",
    "    # fetch vector based features\n",
    "    vector_features = test_fetch_vector_features(q1,q2, word2vec_model)\n",
    "    input_query.extend(vector_features)   \n",
    "    \n",
    "    return np.hstack((np.array(input_query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'How do I can I promote a \"launching soon\" Startup page?'\n",
    "q2 = 'Why do people ask questions everyone Quora they could easily search via Google, Bing or Wikipedia?'\n",
    "q3 = 'What is the free, simplest & fastest way to promote a know page for a new startup?'\n",
    "q4 = 'Why do people ask find on Quora that could simply be googled?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open('NNmodel.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Ensure correct data type for training\n",
    "X_train = np.array(X_train, dtype=np.float64)\n",
    "X_test = np.array(X_test, dtype=np.float64)\n",
    "y_train = np.array(y_train, dtype=np.int64).ravel()\n",
    "y_test = np.array(y_test, dtype=np.int64).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7723\n",
      "F1 Score: 0.6780715396578538\n"
     ]
    }
   ],
   "source": [
    "# Train RandomForest Model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# Compute F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# Define search space for hyperparameters\n",
    "param_space = {\n",
    "    \"n_estimators\": (50, 500),  # Number of trees (int range)\n",
    "    \"max_depth\": (10, 50),  # Maximum depth (int range)\n",
    "    \"min_samples_split\": (2, 10),  # Minimum samples to split a node\n",
    "    \"min_samples_leaf\": (1, 4)  # Minimum samples per leaf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: OrderedDict({'max_depth': 25, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 500})\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bayesian Search\n",
    "bayes_search = BayesSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_space,\n",
    "    n_iter=20,  # Number of iterations (tries different values)\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best Hyperparameters:\", bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    max_depth=25, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=9, \n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Uses all CPU cores for faster training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "y_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.3946886965636049\n"
     ]
    }
   ],
   "source": [
    "# Compute F1 score for each threshold\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy: 0.7516\n",
      "New F1 Score: 0.7252\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "y_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Apply the best threshold\n",
    "y_pred_adjusted = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate the new predictions\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "new_accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "new_f1 = f1_score(y_test, y_pred_adjusted)\n",
    "\n",
    "print(f\"New Accuracy: {new_accuracy:.4f}\")\n",
    "print(f\"New F1 Score: {new_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5293, 1028],\n",
       "       [1172, 2507]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# for random forest model\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING READY TO BUILD A WEBSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_common_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_total_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_token_features(q1,q2):\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_length_features(q1,q2):\n",
    "    \n",
    "    length_features = [0.0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    \n",
    "    return length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_vector_features(q1,q2, word2vec_model):\n",
    "  \n",
    "    # Tokenize using NLTK\n",
    "   q1_tokens = word_tokenize(q1.lower())\n",
    "   q2_tokens = word_tokenize(q2.lower())\n",
    "\n",
    "   q1_vector = sentence_to_vector(q1_tokens, word2vec_model)\n",
    "   q2_vector = sentence_to_vector(q2_tokens, word2vec_model)\n",
    "\n",
    "    # Compute additional feature representations\n",
    "   abs_diff = np.abs(q1_vector - q2_vector)  # |q1 - q2|\n",
    "   elementwise_mult = q1_vector * q2_vector  # q1 * q2\n",
    "\n",
    "    # Combine all features\n",
    "   vector_features = np.hstack((q1_vector, q2_vector, abs_diff, elementwise_mult))\n",
    "\n",
    "   return vector_features  # Return the feature vector only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_point_creator(q1,q2):\n",
    "    \n",
    "    input_query = []\n",
    "    \n",
    "    # preprocess\n",
    "    q1 = preprocess(q1)\n",
    "    q2 = preprocess(q2)\n",
    "    \n",
    "    # fetch basic features\n",
    "    input_query.append(len(q1))\n",
    "    input_query.append(len(q2))\n",
    "    \n",
    "    input_query.append(len(q1.split(\" \")))\n",
    "    input_query.append(len(q2.split(\" \")))\n",
    "    \n",
    "    input_query.append(test_common_words(q1,q2))\n",
    "    input_query.append(test_total_words(q1,q2))\n",
    "    input_query.append(round(test_common_words(q1,q2)/test_total_words(q1,q2),2))\n",
    "    \n",
    "    # fetch token features\n",
    "    token_features = test_fetch_token_features(q1,q2)\n",
    "    input_query.extend(token_features)\n",
    "    \n",
    "    # fetch length based features\n",
    "    length_features = test_fetch_length_features(q1,q2)\n",
    "    input_query.extend(length_features)\n",
    "   \n",
    "    # fetch vector based features\n",
    "    vector_features = test_fetch_vector_features(q1,q2, word2vec_model)\n",
    "    input_query.extend(vector_features)   \n",
    "    \n",
    "    return np.hstack((np.array(input_query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'How do I can I promote a \"launching soon\" Startup page?'\n",
    "q2 = 'Why do people ask questions everyone Quora they could easily search via Google, Bing or Wikipedia?'\n",
    "q3 = 'What is the free, simplest & fastest way to promote a know page for a new startup?'\n",
    "q4 = 'Why do people ask find on Quora that could simply be googled?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "query_features = query_point_creator(q2, q4).reshape(1, -1)\n",
    "prediction = rf_model.predict(query_features)\n",
    "print(prediction)  # Outputs 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf_model,open('model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
